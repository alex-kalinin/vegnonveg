{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception Transfer Learning\n",
    "\n",
    "The goal of this notebook is to use bigdl to retrain last layer of imported inception_v1 model from Caffe, used for Imagenet.  Aims to use transfer learning to classify a dataset of flower images among 5 categories of flowers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:21:52.580834Z",
     "start_time": "2017-09-14T18:21:52.568272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x10c159510>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify if the spark context was initialized \n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:21:53.016289Z",
     "start_time": "2017-09-14T18:21:52.582564Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import all the required packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join, basename\n",
    "import struct\n",
    "import json\n",
    "from scipy import misc\n",
    "import datetime as dt\n",
    "\n",
    "from bigdl.nn.layer import *\n",
    "from optparse import OptionParser\n",
    "from bigdl.nn.criterion import *\n",
    "from bigdl.optim.optimizer import *\n",
    "from bigdl.util.common import *\n",
    "from bigdl.dataset.transformer import *\n",
    "from bigdl.nn.initialization_method import *\n",
    "from transformer import *\n",
    "from imagenet import *\n",
    "from transformer import Resize\n",
    "\n",
    "# if you want to train on whole imagenet\n",
    "#from bigdl.dataset import imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:21:53.211210Z",
     "start_time": "2017-09-14T18:21:53.018338Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%pylab inline\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:21:54.334664Z",
     "start_time": "2017-09-14T18:21:54.323485Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper func to read the files from disk\n",
    "def read_local_path(folder, has_label=True):\n",
    "    \"\"\"\n",
    "    :param folder: local directory (str)\n",
    "    :param has_label: does image have label (bool)\n",
    "    :return: list of (image path , label) tuples\n",
    "    \"\"\"\n",
    "    # read directory, create map\n",
    "    dirs = listdir(folder)\n",
    "    # print \"local path: \", folder\n",
    "    # print \"listdir: \", dirs\n",
    "    # create a list of (image path , label) tuples\n",
    "    image_paths = []\n",
    "    #append image path to the label (ex: )\n",
    "    if has_label:\n",
    "        dirs.sort()\n",
    "        for d in dirs:\n",
    "            for f in listdir(join(folder, d)):\n",
    "                image_paths.append((join(join(folder, d), f), dirs.index(d) + 1))\n",
    "    else:\n",
    "        for f in dirs:\n",
    "            image_paths.append((join(folder, f), -1))\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:21:55.168350Z",
     "start_time": "2017-09-14T18:21:55.152085Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper func to read the files from disk\n",
    "def read_local(sc, folder, normalize=255.0, has_label=True):\n",
    "    \"\"\"\n",
    "    Read images from local directory\n",
    "    :param sc: spark context\n",
    "    :param folder: local directory\n",
    "    :param normalize: normalization value\n",
    "    :param has_label: whether the image folder contains label\n",
    "    :return: RDD of sample\n",
    "    \"\"\"\n",
    "    # read directory, create image paths list\n",
    "    image_paths = read_local_path(folder, has_label)\n",
    "    # print \"BEFORE PARALLELIZATION: \", image_paths\n",
    "    # create rdd\n",
    "    image_paths_rdd = sc.parallelize(image_paths)\n",
    "    # print image_paths_rdd\n",
    "    feature_label_rdd = image_paths_rdd.map(lambda path_label: (misc.imread(path_label[0]), np.array(path_label[1]))) \\\n",
    "        .map(lambda img_label:\n",
    "             (Resize(256, 256)(img_label[0]), img_label[1])) \\\n",
    "        .map(lambda feature_label:\n",
    "             (((feature_label[0] & 0xff) / normalize).astype(\"float32\"), feature_label[1]))\n",
    "    # print \"feature_label_rdd\", feature_label_rdd\n",
    "    return feature_label_rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes an input, if the input is a list, it insert into index 0 spot, such that the real data starts from index 1. Returns back a dictionary with key being the index and value the list of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:21:56.462823Z",
     "start_time": "2017-09-14T18:21:56.455936Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scala_T(input_T):\n",
    "    \"\"\"\n",
    "    Helper function for building Inception layers. Transforms a list of numbers to a dictionary with ascending keys \n",
    "    and 0 appended to the front. Ignores dictionary inputs. \n",
    "    \n",
    "    :param input_T: either list or dict\n",
    "    :return: dictionary with ascending keys and 0 appended to front {0: 0, 1: realdata_1, 2: realdata_2, ...}\n",
    "    \"\"\"    \n",
    "    if type(input_T) is list:\n",
    "        # insert 0 into first index spot, such that the real data starts from index 1\n",
    "        temp = [0]\n",
    "        temp.extend(input_T)\n",
    "        return dict(enumerate(temp))\n",
    "    # if dictionary, return it back\n",
    "    return input_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are used to create and initiate the inception-v1 model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:21:57.724676Z",
     "start_time": "2017-09-14T18:21:57.677480Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question: What is config?\n",
    "def Inception_Layer_v1(input_size, config, name_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Builds the inception-v1 submodule, a local network, that is stacked in the entire architecture when building\n",
    "    the full model.  \n",
    "    \n",
    "    :param input_size: dimensions of input coming into the local network\n",
    "    :param config: ?\n",
    "    :param name_prefix: string naming the layers of the particular local network\n",
    "    :return: concat container object with all of the Sequential layers' ouput concatenated depthwise\n",
    "    \"\"\"        \n",
    "    \n",
    "    '''\n",
    "    Concat is a container who concatenates the output of it's submodules along the provided dimension: all submodules \n",
    "    take the same inputs, and their output is concatenated.\n",
    "    '''\n",
    "    concat = Concat(2)\n",
    "    \n",
    "    \"\"\"\n",
    "    In the above code, we first create a container Sequential. Then add the layers into the container one by one. The \n",
    "    order of the layers in the model is same with the insertion order. \n",
    "    \n",
    "    \"\"\"\n",
    "    conv1 = Sequential()\n",
    "    \n",
    "    #Adding layes to the conv1 model we jus created\n",
    "    \n",
    "    #SpatialConvolution is a module that applies a 2D convolution over an input image.\n",
    "    conv1.add(SpatialConvolution(input_size, config[1][1], 1, 1, 1, 1).set_name(name_prefix + \"1x1\"))\n",
    "    conv1.add(ReLU(True).set_name(name_prefix + \"relu_1x1\"))\n",
    "    concat.add(conv1)\n",
    "    \n",
    "    conv3 = Sequential()\n",
    "    conv3.add(SpatialConvolution(input_size, config[2][1], 1, 1, 1, 1).set_name(name_prefix + \"3x3_reduce\"))\n",
    "    conv3.add(ReLU(True).set_name(name_prefix + \"relu_3x3_reduce\"))\n",
    "    conv3.add(SpatialConvolution(config[2][1], config[2][2], 3, 3, 1, 1, 1, 1).set_name(name_prefix + \"3x3\"))\n",
    "    conv3.add(ReLU(True).set_name(name_prefix + \"relu_3x3\"))\n",
    "    concat.add(conv3)\n",
    "    \n",
    "    \n",
    "    conv5 = Sequential()\n",
    "    conv5.add(SpatialConvolution(input_size,config[3][1], 1, 1, 1, 1).set_name(name_prefix + \"5x5_reduce\"))\n",
    "    conv5.add(ReLU(True).set_name(name_prefix + \"relu_5x5_reduce\"))\n",
    "    conv5.add(SpatialConvolution(config[3][1], config[3][2], 5, 5, 1, 1, 2, 2).set_name(name_prefix + \"5x5\"))\n",
    "    conv5.add(ReLU(True).set_name(name_prefix + \"relu_5x5\"))\n",
    "    concat.add(conv5)\n",
    "    \n",
    "    \n",
    "    pool = Sequential()\n",
    "    pool.add(SpatialMaxPooling(3, 3, 1, 1, 1, 1, to_ceil=True).set_name(name_prefix + \"pool\"))\n",
    "    pool.add(SpatialConvolution(input_size, config[4][1], 1, 1, 1, 1).set_name(name_prefix + \"pool_proj\"))\n",
    "    pool.add(ReLU(True).set_name(name_prefix + \"relu_pool_proj\"))\n",
    "    concat.add(pool).set_name(name_prefix + \"output\")\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Inception_v1_NoAuxClassifier(class_num):\n",
    "    model = Sequential()\n",
    "    model.add(SpatialConvolution(3, 64, 7, 7, 2, 2, 3, 3, 1, False).set_name(\"conv1/7x7_s2\"))\n",
    "    model.add(ReLU(True).set_name(\"conv1/relu_7x7\"))\n",
    "    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True).set_name(\"pool1/3x3_s2\"))\n",
    "    model.add(SpatialCrossMapLRN(5, 0.0001, 0.75).set_name(\"pool1/norm1\"))\n",
    "    model.add(SpatialConvolution(64, 64, 1, 1, 1, 1).set_name(\"conv2/3x3_reduce\"))\n",
    "    model.add(ReLU(True).set_name(\"conv2/relu_3x3_reduce\"))\n",
    "    model.add(SpatialConvolution(64, 192, 3, 3, 1, 1, 1, 1).set_name(\"conv2/3x3\"))\n",
    "    model.add(ReLU(True).set_name(\"conv2/relu_3x3\"))\n",
    "    model.add(SpatialCrossMapLRN(5, 0.0001, 0.75).set_name(\"conv2/norm2\"))\n",
    "    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True).set_name(\"pool2/3x3_s2\"))\n",
    "    model.add(Inception_Layer_v1(192, scala_T([scala_T([64]), scala_T(\n",
    "         [96, 128]), scala_T([16, 32]), scala_T([32])]), \"inception_3a/\"))\n",
    "    model.add(Inception_Layer_v1(256, scala_T([scala_T([128]), scala_T(\n",
    "         [128, 192]), scala_T([32, 96]), scala_T([64])]), \"inception_3b/\"))\n",
    "    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True))\n",
    "    model.add(Inception_Layer_v1(480, scala_T([scala_T([192]), scala_T(\n",
    "         [96, 208]), scala_T([16, 48]), scala_T([64])]), \"inception_4a/\"))\n",
    "    model.add(Inception_Layer_v1(512, scala_T([scala_T([160]), scala_T(\n",
    "         [112, 224]), scala_T([24, 64]), scala_T([64])]), \"inception_4b/\"))\n",
    "    model.add(Inception_Layer_v1(512, scala_T([scala_T([128]), scala_T(\n",
    "         [128, 256]), scala_T([24, 64]), scala_T([64])]), \"inception_4c/\"))\n",
    "    model.add(Inception_Layer_v1(512, scala_T([scala_T([112]), scala_T(\n",
    "         [144, 288]), scala_T([32, 64]), scala_T([64])]), \"inception_4d/\"))\n",
    "    model.add(Inception_Layer_v1(528, scala_T([scala_T([256]), scala_T(\n",
    "         [160, 320]), scala_T([32, 128]), scala_T([128])]), \"inception_4e/\"))\n",
    "    model.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True))\n",
    "    model.add(Inception_Layer_v1(832, scala_T([scala_T([256]), scala_T(\n",
    "         [160, 320]), scala_T([32, 128]), scala_T([128])]), \"inception_5a/\"))\n",
    "    model.add(Inception_Layer_v1(832, scala_T([scala_T([384]), scala_T(\n",
    "         [192, 384]), scala_T([48, 128]), scala_T([128])]), \"inception_5b/\"))\n",
    "    model.add(SpatialAveragePooling(7, 7, 1, 1).set_name(\"pool5/7x7_s1\"))\n",
    "    model.add(Dropout(0.4).set_name(\"pool5/drop_7x7_s1\"))\n",
    "    model.add(View([1024], num_input_dims=3))\n",
    "    model.add(Linear(1024, class_num).set_name(\"loss3/classifier_flowers\"))\n",
    "    model.add(LogSoftMax().set_name(\"loss3/loss3\"))\n",
    "    model.reset()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:21:58.734053Z",
     "start_time": "2017-09-14T18:21:58.559850Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Inception_v1(class_num):\n",
    "    \"\"\"\n",
    "    Builds the entire network using Inception architecture  \n",
    "    \n",
    "    :param class_num: number of categories of classification\n",
    "    :return: entire model architecture \n",
    "    \"\"\"\n",
    "    #contains first 3 inception modules\n",
    "    feature1 = Sequential()\n",
    "    \n",
    "    feature1.add(SpatialConvolution(3, 64, 7, 7, 2, 2, 3, 3, 1, False).set_name(\"conv1/7x7_s2\"))\n",
    "    feature1.add(ReLU(True).set_name(\"conv1/relu_7x7\"))\n",
    "    feature1.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True).set_name(\"pool1/3x3_s2\"))\n",
    "    feature1.add(SpatialCrossMapLRN(5, 0.0001, 0.75).set_name(\"pool1/norm1\"))\n",
    "    feature1.add(SpatialConvolution(64, 64, 1, 1, 1, 1).set_name(\"conv2/3x3_reduce\"))\n",
    "    feature1.add(ReLU(True).set_name(\"conv2/relu_3x3_reduce\"))\n",
    "    feature1.add(SpatialConvolution(64, 192, 3, 3, 1, 1, 1, 1).set_name(\"conv2/3x3\"))\n",
    "    feature1.add(ReLU(True).set_name(\"conv2/relu_3x3\"))\n",
    "    feature1.add(SpatialCrossMapLRN(5, 0.0001, 0.75).set_name(\"conv2/norm2\"))\n",
    "    feature1.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True).set_name(\"pool2/3x3_s2\"))\n",
    "    feature1.add(Inception_Layer_v1(192,scala_T([scala_T([64]), scala_T([96, 128]),scala_T([16, 32]), scala_T([32])]),\n",
    "                                    \"inception_3a/\"))\n",
    "    feature1.add(Inception_Layer_v1(256, scala_T([scala_T([128]), scala_T([128, 192]), scala_T([32, 96]), scala_T([64])]),\n",
    "                                    \"inception_3b/\"))\n",
    "    feature1.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True).set_name(\"pool3/3x3_s2\"))\n",
    "    feature1.add(Inception_Layer_v1(480, scala_T([scala_T([192]), scala_T([96, 208]), scala_T([16, 48]), scala_T([64])]),\n",
    "                                    \"inception_4a/\"))\n",
    "    # 1st classification ouput after 3 inception subnetworks\n",
    "    output1 = Sequential()\n",
    "    output1.add(SpatialAveragePooling(5, 5, 3, 3, ceil_mode=True).set_name(\"loss1/ave_pool\"))\n",
    "    output1.add(SpatialConvolution(512, 128, 1, 1, 1, 1).set_name(\"loss1/conv\"))\n",
    "    output1.add(ReLU(True).set_name(\"loss1/relu_conv\"))\n",
    "    output1.add(View([128 * 4 * 4], num_input_dims = 3))\n",
    "    output1.add(Linear(128 * 4 * 4, 1024).set_name(\"loss1/fc\"))\n",
    "    output1.add(ReLU(True).set_name(\"loss1/relu_fc\"))\n",
    "    output1.add(Dropout(0.7).set_name(\"loss1/drop_fc\"))\n",
    "    output1.add(Linear(1024, class_num).set_name(\"loss1/classifier_5classes\"))\n",
    "    output1.add(LogSoftMax().set_name(\"loss1/loss\"))\n",
    "\n",
    "    # contains next 3 inception submodules\n",
    "    feature2 = Sequential()\n",
    "    feature2.add(Inception_Layer_v1(512, scala_T([scala_T([160]), scala_T([112, 224]),scala_T([24, 64]), scala_T([64])]),\n",
    "                                    \"inception_4b/\"))\n",
    "    feature2.add(Inception_Layer_v1(512, scala_T([scala_T([128]), scala_T([128, 256]),scala_T([24, 64]), scala_T([64])]),\n",
    "                                    \"inception_4c/\"))\n",
    "    feature2.add(Inception_Layer_v1(512, scala_T([scala_T([112]), scala_T([144, 288]), scala_T([32, 64]), scala_T([64])]),\n",
    "                                    \"inception_4d/\"))\n",
    "    # 2nd classification output after 3 more inception subnetworks\n",
    "    output2 = Sequential()\n",
    "    output2.add(SpatialAveragePooling(5, 5, 3, 3).set_name(\"loss2/ave_pool\"))\n",
    "    output2.add(SpatialConvolution(528, 128, 1, 1, 1, 1).set_name(\"loss2/conv\"))\n",
    "    output2.add(ReLU(True).set_name(\"loss2/relu_conv\"))\n",
    "    output2.add(View([128 * 4 * 4], num_input_dims=3))\n",
    "    output2.add(Linear(128 * 4 * 4, 1024).set_name(\"loss2/fc\"))\n",
    "    output2.add(ReLU(True).set_name(\"loss2/relu_fc\"))\n",
    "    output2.add(Dropout(0.7).set_name(\"loss2/drop_fc\"))\n",
    "    output2.add(Linear(1024, class_num).set_name(\"loss2/classifier_5classes\"))\n",
    "    output2.add(LogSoftMax().set_name(\"loss2/loss\"))\n",
    "\n",
    "    # final 3 inception submodules followed by linear/softmax\n",
    "    output3 = Sequential()\n",
    "    output3.add(Inception_Layer_v1(528, scala_T([scala_T([256]), scala_T([160, 320]), scala_T([32, 128]), scala_T([128])]),\n",
    "                                   \"inception_4e/\"))\n",
    "    output3.add(SpatialMaxPooling(3, 3, 2, 2, to_ceil=True).set_name(\"pool4/3x3_s2\"))\n",
    "    output3.add(Inception_Layer_v1(832, scala_T([scala_T([256]), scala_T([160, 320]), scala_T([32, 128]), scala_T([128])]),\n",
    "                                   \"inception_5a/\"))\n",
    "    output3.add(Inception_Layer_v1(832,scala_T([scala_T([384]), scala_T([192, 384]),scala_T([48, 128]), scala_T([128])]),\n",
    "                                   \"inception_5b/\"))\n",
    "    output3.add(SpatialAveragePooling(7, 7, 1, 1).set_name(\"pool5/7x7_s1\"))\n",
    "    output3.add(Dropout(0.4).set_name(\"pool5/drop_7x7_s1\"))\n",
    "    output3.add(View([1024], num_input_dims=3))\n",
    "    output3.add(Linear(1024, class_num).set_name(\"loss3/classifier_5classes\"))\n",
    "    output3.add(LogSoftMax().set_name(\"loss3/loss3\"))\n",
    "\n",
    "    # Attach the separate Sequential layers to create the whole model\n",
    "    split2 = Concat(2).set_name(\"split2\")\n",
    "    split2.add(output3)\n",
    "    split2.add(output2)\n",
    "\n",
    "    #create a branch starting from feature2 upwards\n",
    "    mainBranch = Sequential()\n",
    "    mainBranch.add(feature2)\n",
    "    mainBranch.add(split2)\n",
    "\n",
    "    #concatenate the mainBranch with output1\n",
    "    split1 = Concat(2).set_name(\"split1\")\n",
    "    split1.add(mainBranch)\n",
    "    split1.add(output1)\n",
    "\n",
    "    #Attach feature1 to the rest of the model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(feature1)\n",
    "    model.add(split1)\n",
    "\n",
    "    model.reset()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:21:59.347703Z",
     "start_time": "2017-09-14T18:21:59.337098Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_inception_data(folder, file_type=\"image\", data_type=\"train\", normalize=255.0):\n",
    "    \"\"\"\n",
    "    Builds the entire network using Inception architecture  \n",
    "    \n",
    "    :param class_num: number of categories of classification\n",
    "    :return: entire model architecture \n",
    "    \"\"\"\n",
    "    #Getting the path of our data\n",
    "    path = os.path.join(folder, data_type)\n",
    "    if \"seq\" == file_type:\n",
    "        #return imagenet.read_seq_file(sc, path, normalize) #-- incase if we are trying to read the orig imagenet data\n",
    "        return read_seq_file(sc, path, normalize)\n",
    "    elif \"image\" == file_type:\n",
    "        #return imagenet.read_local(sc, path, normalize)\n",
    "        return read_local(sc, path, normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T16:53:47.651891Z",
     "start_time": "2017-09-14T16:53:47.644313Z"
    }
   },
   "source": [
    "## Creating the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:22:00.747009Z",
     "start_time": "2017-09-14T18:22:00.479356Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initializing BigDL engine\n",
    "init_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:22:01.245271Z",
     "start_time": "2017-09-14T18:22:01.241397Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# paths for datasets, saving checkpoints \n",
    "\n",
    "DATA_PATH = \"./sample_images/\"\n",
    "checkpoint_path = \"./sample_images/checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:22:04.798622Z",
     "start_time": "2017-09-14T18:22:02.435182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialMaxPooling\n",
      "creating: createSpatialCrossMapLRN\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialCrossMapLRN\n",
      "creating: createSpatialMaxPooling\n",
      "creating: createConcat\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialMaxPooling\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createConcat\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialMaxPooling\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialMaxPooling\n",
      "creating: createConcat\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialMaxPooling\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createConcat\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialMaxPooling\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createConcat\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialMaxPooling\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createConcat\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialMaxPooling\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createConcat\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialMaxPooling\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialMaxPooling\n",
      "creating: createConcat\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialMaxPooling\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createConcat\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSequential\n",
      "creating: createSpatialMaxPooling\n",
      "creating: createSpatialConvolution\n",
      "creating: createReLU\n",
      "creating: createSpatialAveragePooling\n",
      "creating: createDropout\n",
      "creating: createView\n",
      "creating: createLinear\n",
      "creating: createLogSoftMax\n"
     ]
    }
   ],
   "source": [
    "#providing the no of classes in the dataset to model (5 for flowers)\n",
    "classNum = 5\n",
    "\n",
    "# Instantiating the model the model\n",
    "# inception_model = Inception_v1(classNum)  #-- main inception-v1 model\n",
    "inception_model = Inception_v1_NoAuxClassifier(classNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import weights from Caffe Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:35:21.545707Z",
     "start_time": "2017-09-14T18:35:21.540522Z"
    }
   },
   "source": [
    "Download the pre-trained 'Inception v1 caffe model' from the link : https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:22:13.685729Z",
     "start_time": "2017-09-14T18:22:10.361537Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path, names of the downlaoded pre-trained caffe models\n",
    "caffe_prototxt = 'bvlc_googlenet.prototxt'\n",
    "caffe_model = 'bvlc_googlenet.caffemodel'\n",
    "\n",
    "# loading the weights to the BigDL inception model, EXCEPT the weights for the last fc layer (classification layer)\n",
    "model = Model.load_caffe(inception_model, caffe_prototxt, caffe_model, match_all=False, bigdl_type=\"float\")\n",
    "\n",
    "# if we want to export the whole caffe model including definition, this can be used.\n",
    "#model = Model.load_caffe_model(inception_model, caffe_prototxt, caffe_model, match_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T16:54:24.325266Z",
     "start_time": "2017-09-14T16:54:24.321799Z"
    }
   },
   "source": [
    "## Testing the pre-trained model on Flowers\n",
    "\n",
    "Download the flower images into the \"sample_images\" folder.\n",
    "```\n",
    "cd ./sample_images\n",
    "curl -O http://download.tensorflow.org/example_images/flower_photos.tgz\n",
    "tar xzf flower_photos.tgz\n",
    "```\n",
    "\n",
    "The goal is to use the pre-trained model to predict an image of a flower to one of the 5 categories to verify model is capable of making a prediction, even if very off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:22:13.707882Z",
     "start_time": "2017-09-14T18:22:13.687778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "# Get the flower categories\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "labels = listdir(\"./sample_images/flower_photos\")\n",
    "print \"labels: \", labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Helper function to make sure image width or height is no smaller than 224x224\n",
    "'''\n",
    "def adjust_dimensions(input_img):\n",
    "    \n",
    "    dimensions = input_img.getbbox()\n",
    "    if dimensions[2] < 224:\n",
    "        input_img = input_img.resize((224,dimensions[3]))\n",
    "        dimensions = input_img.getbbox()\n",
    "        # print \"1\", dimensions\n",
    "    if dimensions[3] < 224:\n",
    "        input_img = input_img.resize((dimensions[2],224))\n",
    "        # print \"2\", input_img.getbbox()\n",
    "    return input_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Pre-processing: \n",
    "From jpg to RDD format for BigDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:22:16.230077Z",
     "start_time": "2017-09-14T18:22:16.154725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accepted image dimensions:  (0, 0, 500, 330)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Convert the test image to an Image object\n",
    "Note: Images in vegnonveg-sample are large and maybe need to be cropped/resized before being trained on.\n",
    "'''\n",
    "from PIL import Image # for seeing image\n",
    "import cv2 # converting img to numpy array (RGB to BGR) \n",
    "\n",
    "sample_images_path = \"./sample_images/flower_photos/sunflowers/\"\n",
    "input_str = '1008566138_6927679c8a.jpg'\n",
    "input_img = Image.open(sample_images_path + input_str)\n",
    "input_img = adjust_dimensions(input_img)\n",
    "print \"accepted image dimensions: \", input_img.getbbox()\n",
    "# DISPLAY IMAGE HERE\n",
    "input_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:22:17.069037Z",
     "start_time": "2017-09-14T18:22:17.060352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 500, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Convert Image object into a 3d numpy array representing BGR of each pixel (for bigdl)\n",
    "'''\n",
    "# img = cv2.imread(sample_images_path + input_str)  \n",
    "# # print img\n",
    "img = np.array(input_img)\n",
    "img = img[:,:,::-1].copy() #invert RGB representation to BGR for each pixel in img\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:22:19.333099Z",
     "start_time": "2017-09-14T18:22:19.325927Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Normalize, crop, finish pre-processing of image so it can be fed to rdd[sample] for bigdl.\n",
    "'''\n",
    "# defining the transformer, which we will use to pre-process our test image\n",
    "img_rows = 224\n",
    "img_cols = 224\n",
    "\n",
    "\n",
    "transform_input = Transformer([Crop(img_rows, img_cols, \"center\"),\n",
    "                                        ChannelNormalizer(0.485, 0.456, 0.406, 0.229, 0.224, 0.225),\n",
    "                                        TransposeToTensor(False)\n",
    "                                        ])\n",
    "# pre-processing the img, feature transformation decreases training time\n",
    "img_tranx = transform_input(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:22:21.061480Z",
     "start_time": "2017-09-14T18:22:21.007343Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Converting the image to 'Sample' format which BigDL expects. \n",
    "'''\n",
    "label = np.array(1) #label of dandelion\n",
    "img_to_model = Sample.from_ndarray(img_tranx, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:22:22.317339Z",
     "start_time": "2017-09-14T18:22:22.024446Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Converting image from 'Sample' format into RDD format\n",
    "'''\n",
    "img_data_rdd = sc.parallelize([img_to_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:22:26.529253Z",
     "start_time": "2017-09-14T18:22:22.904398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# predicting the image using our model\n",
    "predict_result = model.predict_class(img_data_rdd)\n",
    "pred_index = predict_result.collect()[0]\n",
    "print pred_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:22:27.321644Z",
     "start_time": "2017-09-14T18:22:27.314443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roses\n"
     ]
    }
   ],
   "source": [
    "# printing out the category \n",
    "if pred_index > classNum - 1 :\n",
    "    pred_index = pred_index % classNum\n",
    "    \n",
    "class_predicted = str(labels[pred_index - 1])\n",
    "print (class_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roses\n",
      "dandelion\n",
      "roses\n",
      "daisy\n",
      "daisy\n",
      "daisy\n",
      "daisy\n",
      "daisy\n",
      "daisy\n",
      "sunflowers\n",
      "roses\n",
      "daisy\n",
      "sunflowers\n",
      "roses\n",
      "roses\n",
      "daisy\n",
      "roses\n",
      "daisy\n",
      "tulips\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "GOAL: Predicts the first 20 images in a specified flower folder using the pre-trained model\n",
    "'''\n",
    "from PIL import Image # for seeing image\n",
    "import cv2 # converting img to numpy array (RGB to BGR) \n",
    "\n",
    "# get local path of each image\n",
    "flower = \"sunflowers\"\n",
    "dand_path = \"./sample_images/flower_photos/\" + flower + \"/\"\n",
    "imgs = listdir(dand_path)\n",
    "\n",
    "# predict first 20 images\n",
    "for img in imgs[0:19]:\n",
    "    input_img = Image.open(dand_path + img)\n",
    "    input_img = adjust_dimensions(input_img)\n",
    "    \n",
    "    # convert img to np.array form\n",
    "    img_bgr = np.array(input_img)\n",
    "    img_bgr = img_bgr[:,:,::-1].copy()\n",
    "    img_tranx = transform_input(img_bgr)   \n",
    "    \n",
    "    #get label of flower\n",
    "    label = np.array(labels.index(flower)) \n",
    "    \n",
    "    # converting to 'Sample' format which BigDL expects. \n",
    "    img_to_model = Sample.from_ndarray(img_tranx, label)    \n",
    "    \n",
    "    # converting from 'Sample' format into RDD format\n",
    "    img_data_rdd = sc.parallelize([img_to_model])\n",
    "    \n",
    "    # predicting the image using our model\n",
    "    predict_result = model.predict_class(img_data_rdd)\n",
    "    pred_index = predict_result.collect()[0]   \n",
    "\n",
    "    # printing out the category \n",
    "    if pred_index > classNum:\n",
    "        print pred_index\n",
    "        pred_index = pred_index % classNum\n",
    "    class_predicted = str(labels[pred_index - 1])\n",
    "    print (class_predicted)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: 2nd attempt: Use a mapping function to create array of Samples containing first 20 images, then call model.predict_class()\n",
    "Goal: Predict first 20 images in the \"dandelion\" folder using un-trained model.\n",
    "ERROR: py4j.Py4JException: Method modelPredictClass([class com.intel.analytics.bigdl.nn.Sequential, class java.util.ArrayList]) does not exist\n",
    "'''\n",
    "from PIL import Image # for seeing image\n",
    "import cv2 # converting img to numpy array (RGB to BGR) \n",
    "\n",
    "def map_groundtruth_label(l):\n",
    "    return l[0] - 1\n",
    "# defining the tranformer, which we will use to pre-process our test image\n",
    "\n",
    "img_rows = 224\n",
    "img_cols = 224\n",
    "\n",
    "\n",
    "transform_input = Transformer([Crop(img_rows, img_cols, \"center\"),\n",
    "                                        Flip(0.5),\n",
    "                                        ChannelNormalizer(0.485, 0.456, 0.406, 0.229, 0.224, 0.225),\n",
    "                                        TransposeToTensor(False)\n",
    "                                        ])\n",
    "dand_path = \"./sample_images/flower_photos/dandelion/\"\n",
    "imgs = listdir(dand_path)\n",
    "\n",
    "#get paths\n",
    "img_paths = []\n",
    "for img in imgs[0:20]:\n",
    "    img_paths.append((dand_path+img, 1))\n",
    "    \n",
    "#turn img_paths into labelled rdds\n",
    "image_paths_rdd = sc.parallelize(img_paths)\n",
    "\n",
    "feature_label_rdd = image_paths_rdd.map(lambda path_label: (misc.imread(path_label[0]), np.array(path_label[1]))) \\\n",
    "        .map(lambda img_label:\n",
    "             (Resize(256, 256)(img_label[0]), img_label[1])) \\\n",
    "        .map(lambda feature_label:\n",
    "             (((feature_label[0] & 0xff) / 255.0).astype(\"float32\"), feature_label[1]))\n",
    "\n",
    "#turn to sample form for predictions \n",
    "img_data = feature_label_rdd.map(\n",
    "                lambda features_label: (train_transformer(features_label[0]), features_label[1])).map(\n",
    "                lambda features_label: Sample.from_ndarray(features_label[0], features_label[1] + 1))\n",
    "\n",
    "# predicting the image using our model\n",
    "print \"Predictions: \"\n",
    "res = model.predict_class(img_data)\n",
    "print res.collect()\n",
    "\n",
    "print \"True Labels: \"\n",
    "print ', '.join(str(map_groundtruth_label(s.label)) for s in img_data.take(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T17:27:45.341955Z",
     "start_time": "2017-09-14T17:27:45.337081Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### To-do:\n",
    "- pre-req : Defined inception_v1 model in BigDL and load it with Caffe model's weights\n",
    "- pre-req: removed the last layer of the model, added a new layer with 'num_class' we have in our data-set(5)\n",
    "\n",
    "#### next steps :\n",
    "- freeze all the layers except last fc layer\n",
    "- compile the model\n",
    "- train the model on our dataset, keeping all the weights except the last layer\n",
    "- test the trained model on our test dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model for transfer learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Freeze every layer except Fully Connected Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: model.freeze() seems to be not implemented yet.\n",
    "'''\n",
    "# layers_to_freeze = [\"conv1/7x7_s2\", \"conv2/3x3_reduce\", \"conv2/3x3\"]\n",
    "\n",
    "# inception_layers = [\"3a\", \"3b\", \"4a\", \"4b\", \"4c\", \"4d\", \"4e\", \"5a\", \"5b\"]\n",
    "# mini_net_layers = [\"1x1\", \"3x3_reduce\", \"3x3\", \"5x5_reduce\", \"5x5\", \"pool_proj\"]\n",
    "\n",
    "# for i in inception_layers:\n",
    "#     for m in mini_net_layers:\n",
    "#         layers_to_freeze.append(\"inception_\" + i + \"/\" + m)\n",
    "        \n",
    "# inception_model.freeze([layers_to_freeze])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: before training your model, you need to create a **train**, **val**, **test** folder in your **sample_images** folder with the same structure as the **flower_photos** folder.  Split the images in each flower category within **flower_photos** by putting 10 images in **test**, 100 images in **val** and the rest of the images in **train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:11:42.670688Z",
     "start_time": "2017-09-14T18:11:42.048893Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Reading the training and validation data and perform pre-processing \n",
    "'''\n",
    "\n",
    "\n",
    "# the image size expected by the model\n",
    "image_size = 224\n",
    "\n",
    "# image transformer, used for pre-processing the train images \n",
    "train_transformer = Transformer([Crop(image_size, image_size),\n",
    "                                  Flip(0.5),\n",
    "                                  ChannelNormalizer(0.485, 0.456, 0.406, 0.229, 0.224, 0.225),\n",
    "                                  TransposeToTensor(False)])\n",
    "\n",
    "# reading the traning data\n",
    "train_data = get_inception_data(DATA_PATH, \"image\", \"train\").map(\n",
    "                lambda features_label: (train_transformer(features_label[0]), features_label[1])).map(\n",
    "                lambda features_label: Sample.from_ndarray(features_label[0], features_label[1] + 1))\n",
    "\n",
    "\n",
    "# validation data transformer \n",
    "val_transformer = Transformer([Crop(image_size, image_size, \"center\"),\n",
    "                                Flip(0.5),\n",
    "                                ChannelNormalizer(0.485, 0.456, 0.406, 0.229, 0.224, 0.225),\n",
    "                                TransposeToTensor(False)])\n",
    "\n",
    "#reading the validation data\n",
    "val_data = get_inception_data(DATA_PATH, \"image\", \"val\").map(\n",
    "                lambda features_label: (val_transformer(features_label[0]), features_label[1])).map(\n",
    "                lambda features_label: Sample.from_ndarray(features_label[0], features_label[1] + 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:12:02.671967Z",
     "start_time": "2017-09-14T18:11:45.665035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createDefault\n",
      "creating: createSGD\n",
      "creating: createClassNLLCriterion\n",
      "creating: createMaxEpoch\n",
      "creating: createOptimizer\n",
      "creating: createEveryEpoch\n",
      "creating: createEveryEpoch\n",
      "creating: createTop1Accuracy\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "\n",
    "# parameters for \n",
    "batch_size = 16\n",
    "no_epochs = 2\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Optimizer(\n",
    "                model=model,\n",
    "                training_rdd=train_data,\n",
    "                #optim_method=Adam(learningrate=0.002),\n",
    "                optim_method = SGD(learningrate=0.01, learningrate_decay=0.0002),\n",
    "                criterion=ClassNLLCriterion(),\n",
    "                end_trigger=MaxEpoch(no_epochs),\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "\n",
    "# setting checkpoints\n",
    "optimizer.set_checkpoint(EveryEpoch(), checkpoint_path, isOverWrite=False)\n",
    "\n",
    "# setting validation parameters \n",
    "optimizer.set_validation( batch_size=batch_size,\n",
    "                          val_rdd=val_data,\n",
    "                          trigger=EveryEpoch(),\n",
    "                          val_method=[Top1Accuracy()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log the training process to measure loss/accuracy functions while training the network.  This can be visualized on Tensorboard as well.\n",
    "```\n",
    "tensorboard --logdir=/tmp/inception_summaries\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createTrainSummary\n",
      "creating: createSeveralIteration\n",
      "creating: createValidationSummary\n",
      "saving logs to  inception-20171011-105349\n"
     ]
    }
   ],
   "source": [
    "# Log the training process to measure loss/accuracy, can be \n",
    "app_name= 'inception-' + dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_summary = TrainSummary(log_dir='/tmp/inception_summaries',\n",
    "                                     app_name=app_name)\n",
    "train_summary.set_summary_trigger(\"Parameters\", SeveralIteration(50))\n",
    "val_summary = ValidationSummary(log_dir='/tmp/inception_summaries',\n",
    "                                        app_name=app_name)\n",
    "optimizer.set_train_summary(train_summary)\n",
    "optimizer.set_val_summary(val_summary)\n",
    "print \"saving logs to \",app_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashleyzhao/anaconda/envs/inception/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['Normalize', 'random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ashleyzhao/Desktop/BIGDL/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 883, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/ashleyzhao/Desktop/BIGDL/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1040, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "Py4JNetworkError: Error while receiving\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ashleyzhao/anaconda/envs/inception/lib/python2.7/SocketServer.py\", line 290, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/Users/ashleyzhao/anaconda/envs/inception/lib/python2.7/SocketServer.py\", line 318, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/Users/ashleyzhao/anaconda/envs/inception/lib/python2.7/SocketServer.py\", line 331, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:59811)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ashleyzhao/Desktop/BIGDL/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/Users/ashleyzhao/anaconda/envs/inception/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 61] Connection refused\n",
      "  File \"/Users/ashleyzhao/anaconda/envs/inception/lib/python2.7/SocketServer.py\", line 652, in __init__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 61839)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self.handle()\n",
      "  File \"/Users/ashleyzhao/Desktop/BIGDL/spark-2.1.1-bin-hadoop2.7/python/pyspark/accumulators.py\", line 235, in handle\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/Users/ashleyzhao/Desktop/BIGDL/spark-2.1.1-bin-hadoop2.7/python/pyspark/serializers.py\", line 577, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:59811)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-9e205188397d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Boot training process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'pylab inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Optimization Done.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/private/var/folders/vy/655kxsvd2_zghcd7y1ghh76w0000gn/T/spark-61a18945-c846-48c3-8d93-c3e01511ee38/userFiles-4e2cd2d3-681e-4654-858d-c2d2b06ebff4/bigdl-0.2.0-python-api.zip/bigdl/optim/optimizer.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;32m/private/var/folders/vy/655kxsvd2_zghcd7y1ghh76w0000gn/T/spark-61a18945-c846-48c3-8d93-c3e01511ee38/userFiles-4e2cd2d3-681e-4654-858d-c2d2b06ebff4/bigdl-0.2.0-python-api.zip/bigdl/util/common.py\u001b[0m in \u001b[0;36mcallJavaFunc\u001b[0;34m(sc, func, *args)\u001b[0m\n",
      "\u001b[0;32m/Users/ashleyzhao/Desktop/BIGDL/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ashleyzhao/Desktop/BIGDL/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             stackTrace = '\\n\\t at '.join(map(lambda x: x.toString(),\n\u001b[0;32m---> 67\u001b[0;31m                                              e.java_exception.getStackTrace()))\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ashleyzhao/anaconda/envs/inception/lib/python2.7/_abcoll.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ashleyzhao/Desktop/BIGDL/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_collections.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__compute_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             raise TypeError(\"array indices must be integers, not {0}\".format(\n",
      "\u001b[0;32m/Users/ashleyzhao/Desktop/BIGDL/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_collections.py\u001b[0m in \u001b[0;36m__compute_item\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__compute_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mnew_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__compute_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mARRAY_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mARRAY_GET_SUB_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ashleyzhao/Desktop/BIGDL/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_collections.py\u001b[0m in \u001b[0;36m__compute_index\u001b[0;34m(self, key, adjustLast)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__compute_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjustLast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ashleyzhao/Desktop/BIGDL/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_collections.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_return_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ashleyzhao/Desktop/BIGDL/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    879\u001b[0m          \u001b[0;32mif\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \"\"\"\n\u001b[0;32m--> 881\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ashleyzhao/Desktop/BIGDL/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ashleyzhao/Desktop/BIGDL/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    833\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    834\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ashleyzhao/Desktop/BIGDL/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:59811)"
     ]
    }
   ],
   "source": [
    "# Boot training process\n",
    "# ERROR: not enough java heap space, too little RAM issue\n",
    "%pylab inline\n",
    "trained_model = optimizer.optimize()\n",
    "print \"Optimization Done.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our trained model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-14T18:13:28.570236Z",
     "start_time": "2017-09-14T18:13:28.467892Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local path:  ./sample/val\n",
      "listdir:  ['nonveg', 'veg']\n",
      "BEFORE PARALLELIZATION:  [('./sample/val/nonveg/n07710616_21595.JPEG', 1), ('./sample/val/nonveg/n07710616_32372.JPEG', 1), ('./sample/val/veg/n00017222_17493.JPEG', 2), ('./sample/val/veg/n00017222_17592.JPEG', 2)]\n",
      "feature_label_rdd PythonRDD[700] at RDD at PythonRDD.scala:48\n",
      "Predictions: \n",
      "[3, 3, 3, 3]\n",
      "True Labels: \n",
      "1.0, 1.0, 2.0, 2.0\n",
      "creating: createTop1Accuracy\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# image transformer, used for pre-processing the validation images \n",
    "test_transformer = Transformer([Crop(image_size, image_size, \"center\"),\n",
    "                                ChannelNormalizer(0.485, 0.456, 0.406, 0.229, 0.224, 0.225),\n",
    "                                TransposeToTensor(False)])\n",
    "\n",
    "# shouldn't the option to be passed is 'test' here rather than 'val' ? \n",
    "# reading val data \n",
    "# get_inception_data() returns a PythonRDD\n",
    "test_data = get_inception_data(DATA_PATH, \"image\", \"test\").map(\n",
    "                lambda features_label: (test_transformer(features_label[0]), features_label[1])).map(\n",
    "                lambda features_label: Sample.from_ndarray(features_label[0], features_label[1] + 1))\n",
    "\n",
    "def map_groundtruth_label(l):\n",
    "    return l[0] - 1\n",
    "\n",
    "print \"Predictions: \"\n",
    "res = trained_model.predict_class(test_data)\n",
    "print res.collect()\n",
    "\n",
    "print \"True Labels: \"\n",
    "print ', '.join(str(map_groundtruth_label(s.label)) for s in test_data.take(8))\n",
    "# testing the trained model \n",
    "results = trained_model.test(test_data, batch_size, [Top1Accuracy()])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
